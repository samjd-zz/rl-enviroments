# RL Environments: Support Ticket Routing

A Gymnasium-compliant reinforcement learning environment for intelligent support ticket routing in B2B SaaS environments. This project enables RL agents to learn optimal ticket assignment strategies based on agent expertise, workload, ticket type, and priority levels.

## ğŸ¯ Problem Statement

B2B SaaS companies receiving 50+ support tickets daily face challenges with random ticket assignment:
- **Long resolution times** (48+ hours average)
- **Inefficient resource utilization** (agent expertise mismatch)
- **Poor workload distribution** (some agents overloaded, others underutilized)
- **Low customer satisfaction** (< 70% CSAT scores)

This RL environment simulates intelligent routing that considers:
- **Ticket Type**: Technical, Billing, Feature Request, Bug Report, Integration
- **Agent Expertise**: Performance history on different ticket types (0.0-1.0 scores)
- **Current Workload**: Number of open tickets per agent (max 10)
- **Priority Level**: Critical, High, Medium, Low

## ğŸš€ Features

### Core Environment
- **Gymnasium API Compliant**: Full compatibility with modern RL frameworks
- **Highly Configurable**: YAML-based configuration for all environment parameters
- **Multiple RL Libraries**: Ready for Stable Baselines3, RLlib, CleanRL
- **Vectorization Support**: Parallel training with vectorized environments
- **Performance Optimized**: < 1ms per step for fast training (verified)
- **Comprehensive Testing**: 98% test coverage with 145 unit and integration tests
- **Type-Safe**: Full type hints with mypy strict mode compliance

### ğŸ¨ Interactive Streamlit Dashboard (NEW!)
- **Real-Time Simulation**: Step-by-step interactive environment execution
- **Analytics Dashboard**: Multi-episode performance analysis and metrics
- **Configuration UI**: Visual environment parameter tuning with presets
- **Visual Metrics**: Live charts for rewards, queue size, agent workload
- **Preset Modes**: Easy, Balanced, and Hard difficulty configurations
- **Export/Import**: Save and load custom configurations

## ğŸ“‹ Requirements

- Python >= 3.8
- Gymnasium >= 0.29.0
- NumPy >= 1.24.0
- Pandas >= 2.0.0 (for logging)
- Matplotlib >= 3.7.0 (for visualization)

## ğŸ› ï¸ Installation

### From Source

```bash
# Clone repository
git clone <repository-url>
cd rl-enviroments

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Install in development mode
pip install -e .
```

### Dependencies

```bash
pip install gymnasium numpy pandas matplotlib seaborn pyyaml pytest hypothesis mypy black
```

## ğŸ“– Quick Start

### Basic Usage

```python
from rl_environments.ticket_routing import TicketRoutingEnv

# Create environment with default configuration
env = TicketRoutingEnv()

# Reset environment
observation, info = env.reset(seed=42)

# Run episode
for step in range(100):
    # Sample random action (or use trained policy)
    action = env.action_space.sample()
    
    # Execute action
    observation, reward, terminated, truncated, info = env.step(action)
    
    # Render (optional)
    env.render()
    
    if terminated or truncated:
        observation, info = env.reset()

env.close()
```

### Training with Stable Baselines3

```python
from stable_baselines3 import PPO
from stable_baselines3.common.env_checker import check_env
from rl_environments.ticket_routing import TicketRoutingEnv

# Create and validate environment
env = TicketRoutingEnv()
check_env(env)

# Train PPO agent
model = PPO("MultiInputPolicy", env, verbose=1)
model.learn(total_timesteps=100_000)

# Save trained model
model.save("ticket_routing_ppo")

# Evaluate
obs, info = env.reset()
for _ in range(1000):
    action, _states = model.predict(obs, deterministic=True)
    obs, reward, terminated, truncated, info = env.step(action)
    if terminated or truncated:
        print(f"Episode metrics: {info}")
        obs, info = env.reset()
```

### Custom Configuration

```python
from rl_environments.ticket_routing import TicketRoutingEnv
from rl_environments.ticket_routing.core.data_models import EnvironmentConfig

# Load from YAML
config = EnvironmentConfig.from_yaml("config/custom_config.yaml")

# Or create programmatically
config = EnvironmentConfig(
    num_agents=10,
    episode_length=2000,
    max_queue_size=100,
)

env = TicketRoutingEnv(config)
```

### ğŸ¨ Using the Interactive Dashboard

The Streamlit dashboard provides a user-friendly interface for exploring and testing the environment:

```bash
# Launch the dashboard
streamlit run streamlit_app.py
```

Then navigate to `http://localhost:8501` in your browser. The dashboard includes:

1. **ğŸ® Simulator** - Step-by-step interactive environment execution
   - Initialize environment with current configuration
   - Step through episodes manually
   - View real-time metrics and agent states
   - Visualize rewards and queue dynamics

2. **ğŸ“Š Analytics** - Multi-episode performance analysis
   - Configure analysis parameters (episodes, length, agents)
   - Run automated simulations
   - View aggregated performance metrics
   - Compare different configurations

3. **âš™ï¸ Configuration** - Visual environment customization
   - Adjust all environment parameters interactively
   - Preset difficulty modes (Easy, Balanced, Hard)
   - Export/import configurations as JSON
   - Preview configuration impact

See [STREAMLIT_README.md](STREAMLIT_README.md) for detailed dashboard documentation.

## ğŸ—ï¸ Project Structure

```
rl-enviroments/
â”œâ”€â”€ rl_environments/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ ticket_routing/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ core/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ data_models.py       # âœ… Ticket, Agent, State dataclasses
â”‚       â”‚   â”œâ”€â”€ ticket_generator.py  # âœ… Poisson process ticket generation
â”‚       â”‚   â”œâ”€â”€ agent_manager.py     # âœ… Agent pool and workload management
â”‚       â”‚   â”œâ”€â”€ state_manager.py     # âœ… Episode state tracking
â”‚       â”‚   â”œâ”€â”€ reward_calculator.py # âœ… Multi-component reward function
â”‚       â”‚   â””â”€â”€ environment.py       # âœ… Main TicketRoutingEnv class
â”‚       â”œâ”€â”€ utils/
â”‚       â”‚   â””â”€â”€ __init__.py          # âš ï¸ Utils modules TBD
â”‚       â”œâ”€â”€ config/
â”‚       â”‚   â””â”€â”€ default_config.yaml  # âœ… Default environment configuration
â”‚       â””â”€â”€ tests/
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ test_data_models.py      # âœ… 25 tests
â”‚           â”œâ”€â”€ test_ticket_generator.py # âœ… 25 tests
â”‚           â”œâ”€â”€ test_agent_manager.py    # âœ… 25 tests
â”‚           â”œâ”€â”€ test_state_manager.py    # âœ… 26 tests
â”‚           â”œâ”€â”€ test_reward_calculator.py # âœ… 25 tests
â”‚           â””â”€â”€ test_environment.py      # âœ… 28 tests (98% coverage)
â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ 1_ğŸ®_Simulator.py        # âœ… Interactive environment simulator
â”‚   â”œâ”€â”€ 2_ğŸ“Š_Analytics.py        # âœ… Performance analytics dashboard
â”‚   â””â”€â”€ 3_âš™ï¸_Configuration.py   # âœ… Environment configuration UI
â”œâ”€â”€ examples/                    # âš ï¸ Example scripts TBD
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ idea.md                  # âœ… Initial concept and requirements
â”‚   â”œâ”€â”€ prd.md                   # âœ… Product Requirements Document
â”‚   â”œâ”€â”€ design.md                # âœ… Technical Design Document
â”‚   â””â”€â”€ plan.md                  # âœ… Implementation plan (updated)
â”œâ”€â”€ streamlit_app.py             # âœ… Main Streamlit dashboard
â”œâ”€â”€ STREAMLIT_README.md          # âœ… Dashboard documentation
â”œâ”€â”€ README.md                    # âœ… Project documentation
â”œâ”€â”€ CLAUDE.md                    # âœ… AI development guidelines
â”œâ”€â”€ .clinerules                  # âœ… Project-specific rules
â”œâ”€â”€ requirements.txt             # âœ… Python dependencies
â””â”€â”€ test_smoke.py                # âœ… Smoke test

Legend: âœ… Complete | âš ï¸ Planned/Partial | âŒ Not Started
```

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=rl_environments --cov-report=html

# Run type checking
mypy rl_environments --strict

# Run code formatting
black rl_environments

# Run linting
ruff check rl_environments
```

## ğŸ“Š Environment Specifications

### Observation Space

```python
Dict({
    'current_ticket': Dict({
        'type': Discrete(5),      # Ticket type (0-4)
        'priority': Discrete(4),  # Priority level (0-3)
        'age': Box(0, inf)        # Time since arrival
    }),
    'agents': Dict({
        'expertise': Box(0, 1, shape=(num_agents, 5)),  # Expertise matrix
        'workload': Box(0, 10, shape=(num_agents,)),    # Open tickets
        'availability': MultiBinary(num_agents)         # Available flag
    }),
    'queue_size': Discrete(100),
    'time_step': Discrete(1000)
})
```

### Action Space

```python
Discrete(num_agents)  # Select which agent to assign ticket to
```

### Reward Function

```python
reward = base_reward + expertise_bonus - resolution_penalty - workload_penalty
```

Where:
- **Base Reward**: +10 for successful assignment
- **Expertise Bonus**: +(expertise_score Ã— 5) for matching expertise
- **Resolution Penalty**: -(resolution_time Ã— priority_multiplier Ã— 0.1)
- **Workload Penalty**: -5 if workload imbalance exceeds threshold

## ğŸ“ˆ Performance Metrics

- **Environment Step Time**: < 1ms (for 10 agents, 50 ticket queue)
- **Memory Usage**: < 100MB per instance
- **Vectorization**: Supports 4+ parallel environments
- **Determinism**: Full reproducibility with seeding

## ğŸ“ Documentation

- **[Idea Document](docs/idea.md)**: Problem statement and proposed solution
- **[PRD](docs/prd.md)**: Product requirements and specifications
- **[Design Document](docs/design.md)**: Technical architecture and components
- **[Implementation Plan](docs/plan.md)**: Step-by-step development roadmap

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Make your changes following our coding standards (see CLAUDE.md)
4. Run tests and type checking (`pytest && mypy`)
5. Commit your changes (`git commit -m 'Add amazing feature'`)
6. Push to branch (`git push origin feature/amazing-feature`)
7. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

**Educational Use:** This project is specifically designed for educational and learning purposes. Students, researchers, and practitioners are encouraged to use, study, and extend this code for learning about reinforcement learning environment design.

## ğŸ™ Acknowledgments

- Built with [Gymnasium](https://gymnasium.farama.org/)
- Inspired by real-world B2B SaaS support challenges
- AI-TDD methodology for structured development

## ğŸ“§ Contact

[Your Contact Information]

---

**Project Status**: âœ… Core Complete (74% Overall) | ğŸš§ Examples & Advanced Testing Pending  
**Version**: 0.2.0-beta  
**Last Updated**: 2025-11-14

## ğŸ“Š Current Implementation Status

| Component | Status | Coverage | Notes |
|-----------|--------|----------|-------|
| Core Environment | âœ… Complete | 98% | All core functionality working |
| Unit Tests | âœ… Complete | 98% | 145 tests passing |
| Integration Tests | âœ… Complete | âœ… | Gymnasium compliance verified |
| Streamlit Dashboard | âœ… Complete | âœ… | 3 interactive pages |
| Documentation | âœ… Complete | âœ… | Comprehensive docs |
| Example Scripts | âš ï¸ Planned | - | Random/PPO training examples |
| SB3 Integration Tests | âš ï¸ Planned | - | Compatibility validation |
| Property Tests | âš ï¸ Planned | - | Hypothesis-based testing |
| Tutorial Notebook | âš ï¸ Planned | - | Jupyter walkthrough |

**Ready for**: Environment testing, custom training, interactive simulation  
**Next Steps**: Add example scripts for quick start, SB3 integration tests
